{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import math\n",
    "#TSFRESH\n",
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#ROC\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import roc_curve  \n",
    "from sklearn.metrics import roc_auc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw data file to trip record files\n",
    "\n",
    "def rawToRecord():\n",
    "    print(\"Starting [rawToRecord]...\")\n",
    "    # **Modify List of Input Files:** filename1-part1.csv, filename2-part2.csv\n",
    "    files=[\"part-0001-*.csv\"] \n",
    "    for filename in files:\n",
    "        file = pd.read_csv(filename, error_bad_lines=False, low_memory=False)\n",
    "        for i, x in file.groupby('bookingID'):\n",
    "            if os.path.exists(str(i).join(\".csv\")):\n",
    "                x.to_csv('{}.csv'.format(i), index=False, mode='a') \n",
    "            else:\n",
    "                x.to_csv('{}.csv'.format(i), index=False, mode='w')\n",
    "    print(\"Finish [rawToRecord]...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories trip record files based on label (safe or dangerous driving)\n",
    "\n",
    "def splitRecord():\n",
    "\n",
    "    print(\"Starting [splitRecord]...\")\n",
    "    files = []\n",
    "    files2= []\n",
    "\n",
    "    truth = pd.read_csv(\"label.csv\", error_bad_lines=False)\n",
    "    total_rows = len(truth['bookingID'])\n",
    "    for i in range(total_rows):\n",
    "        if (truth['label'][i] == 0):\n",
    "            files.append(str(truth['bookingID'][i]) + \".csv\")\n",
    "        else:\n",
    "            files2.append(str(truth['bookingID'][i]) + \".csv\")\n",
    "    \n",
    "    # **Modify Directory Path:** ../../Label0 - create folder Label0 and Label1\n",
    "    if not os.path.exists(r'C:\\Users\\LEE\\Desktop\\python\\safety\\deploy\\Label0\\\\'): \n",
    "        os.makedirs(r'C:\\Users\\LEE\\Desktop\\python\\safety\\deploy\\Label0\\\\')\n",
    "    if not os.path.exists(r'C:\\Users\\LEE\\Desktop\\python\\safety\\deploy\\Label1\\\\'):\n",
    "        os.makedirs(r'C:\\Users\\LEE\\Desktop\\python\\safety\\deploy\\Label1\\\\')\n",
    "\n",
    "    for f in files:\n",
    "        if os.path.isfile(f):\n",
    "            shutil.move(f, r'C:\\Users\\LEE\\Desktop\\python\\safety\\deploy\\Label0\\\\')\n",
    "\n",
    "    for f in files2:\n",
    "        if os.path.isfile(f):\n",
    "            shutil.move(f, r'C:\\Users\\LEE\\Desktop\\python\\safety\\deploy\\Label1\\\\')\n",
    "    print(\"Finish [splitRecord]...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combineFiles function : Create 'trainRecord' csv file with balanced number of records from Label0 and Label1\n",
    "# getGroundLabel function : Create 'trainLabel' csv file with records' ID and label\n",
    "\n",
    "def combineFiles():\n",
    "\n",
    "    print(\"Starting [combineFiles]...\")\n",
    "    PATH = r'C:\\Users\\LEE\\Desktop\\python\\safety\\deploy\\\\'\n",
    "    EXT = \"*.csv\"\n",
    "    all_csv_files = [file\n",
    "                     for path,subdir,files in os.walk(PATH)\n",
    "                     for file in glob(os.path.join(path, EXT))]#\n",
    "    dangerous = []\n",
    "    safe = []\n",
    "    trainSet = []\n",
    "    header_saved = False\n",
    "\n",
    "    for i in all_csv_files:\n",
    "        path=os.path.dirname(i)\n",
    "        folderName=os.path.basename(path)\n",
    "        if (folderName == \"Label1\"):\n",
    "            dangerous.append(i)\n",
    "        elif(folderName == \"Label0\"): \n",
    "            safe.append(i)\n",
    "\n",
    "    # construct balanced dataset : **Modify Number of Label 0/1 record:**\n",
    "    trainSet = dangerous[:4000] + safe[:4000] \n",
    "\n",
    "    getGroundLabel(trainSet)\n",
    "\n",
    "    with open('trainRecord.csv','a') as fout:\n",
    "        for tripRecord in trainSet:\n",
    "            with open(tripRecord) as fin:\n",
    "                header = next(fin)\n",
    "                if not header_saved:\n",
    "                    fout.write(header)\n",
    "                    header_saved = True\n",
    "                for line in fin:\n",
    "                    fout.write(line)\n",
    "        fout.close()\n",
    "    print(\"Finish [combineFiles]...\")\n",
    "\n",
    "def getGroundLabel(label):\n",
    "\n",
    "    empty=[]\n",
    "    labelList = []\n",
    "\n",
    "    for i in label:\n",
    "        labelList.append(os.path.basename(i))\n",
    "\n",
    "    truth = pd.read_csv(\"label.csv\", error_bad_lines=False)\n",
    "    total_rows = len(truth['bookingID'])\n",
    "    for i in range(total_rows):\n",
    "        filename = str(truth['bookingID'][i])+ \".csv\"\n",
    "        if filename not in labelList:\n",
    "            empty.append(i)\n",
    "    truth = truth.drop(truth.index[empty])\n",
    "    truth = truth.drop_duplicates(subset='bookingID', keep='first')\n",
    "    truth.to_csv(\"trainLabel.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess function : \n",
    "##Create new columns [totalAcceleration, totalGyro] in trainRecord\n",
    "## totalAcceleration - calculate magnitude for acceleration\n",
    "## totalGyro - calculate magnitude for angular velocity\n",
    "##Remove irrelevant column and sorting record in trainRecord\n",
    "\n",
    "def preprocess():\n",
    "\n",
    "    print(\"Starting [preprocess]...\")\n",
    "    df = pd.read_csv(\"trainRecord.csv\", error_bad_lines=False, low_memory=False)\n",
    "    df = df.assign(totalAcceleration=0.0)\n",
    "    df = df.assign(totalGyro=0.0)\n",
    "\n",
    "    total_rows = len(df['bookingID'])\n",
    "    for i in range(total_rows):\n",
    "\n",
    "        X = df[\"acceleration_x\"][i]**(2) + df[\"acceleration_y\"][i]**(2) + df[\"acceleration_z\"][i]**(2)\n",
    "        df.at[i, 'totalAcceleration']= math.sqrt(X)\n",
    "\n",
    "        Y = float(df[\"gyro_x\"][i])**(2) + float(df[\"gyro_y\"][i])**(2) + float(df[\"gyro_z\"][i])**(2)\n",
    "        df.at[i, 'totalGyro']= math.sqrt(Y)\n",
    "\n",
    "    del df['Accuracy']\n",
    "    del df['acceleration_x']\n",
    "    del df['acceleration_y']\n",
    "    del df['acceleration_z']\n",
    "    del df['gyro_x']\n",
    "    del df['gyro_y']\n",
    "    del df['gyro_z']\n",
    "\n",
    "    df = df.groupby('bookingID')\n",
    "    df = df.apply(lambda _df: _df.sort_values(by=['second']))\n",
    "\n",
    "    df.to_csv(\"trainRecord.csv\",index=False)\n",
    "    print(\"Finish [preprocess]...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features function : automatic extract features from trainRecord using TSFRESH\n",
    "## Customize parameter \n",
    "## Able to add custom feature extraction function through adding code in TSFRESH submodule\n",
    "\n",
    "def features():\n",
    "\n",
    "    print(\"Starting [features]...\")\n",
    "    df = pd.read_csv(\"trainRecord.csv\", error_bad_lines=False)\n",
    "    truth = pd.read_csv(\"trainLabel.csv\", error_bad_lines=False)\n",
    "\n",
    "    kind_to_fc_parameters = {\n",
    "    \"Speed\": {\"maximum\": None, \"mean_abs_change\": None,\n",
    "    \"count_above_mean\": None, \"longest_strike_above_mean\": None},\n",
    "\n",
    "    \"totalAcceleration\": {\"maximum\": None, \"mean_abs_change\": None,\n",
    "    \"count_above_mean\": None, \"longest_strike_above_mean\": None},\n",
    "\n",
    "    \"totalGyro\": {\"maximum\": None, \"mean_abs_change\": None,\n",
    "    \"count_above_mean\": None, \"longest_strike_above_mean\": None},\n",
    "\n",
    "    \"Bearing\":{\"mean_abs_change\": None,\n",
    "    \"count_above_mean\": None, \"longest_strike_above_mean\": None}\n",
    "    }\n",
    "\n",
    "    tripLabel = pd.Series(data=truth[\"label\"].values,index = truth[\"bookingID\"].values)\n",
    "    features_filtered_direct = extract_relevant_features(df,tripLabel,\n",
    "        column_id='bookingID', column_sort='second', kind_to_fc_parameters=kind_to_fc_parameters)\n",
    "    print(features_filtered_direct.head())\n",
    "    features_filtered_direct.to_csv(\"trainFeature.csv\",index=False)\n",
    "    print(\"Finish [features]...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function : training 'trainFeature' with RandomForestClassifier algorithm\n",
    "# Hold out validation with 0.2 test size\n",
    "# plot ROC curve\n",
    "\n",
    "def train():\n",
    "\n",
    "    print(\"Starting [train]...\")\n",
    "    X_filtered = pd.read_csv(\"trainFeature.csv\", error_bad_lines=False)\n",
    "    y = pd.read_csv(\"trainLabel.csv\", error_bad_lines=False)\n",
    "    tripLabel = pd.Series(data=y[\"label\"].values,index = y[\"bookingID\"].values)\n",
    "    X_filtered_train, X_filtered_test, y_train, y_test = train_test_split(X_filtered, tripLabel, test_size=.2)\n",
    "\n",
    "    cl2 = RandomForestClassifier(n_estimators=1000)\n",
    "    cl2.fit(X_filtered_train, y_train)\n",
    "    probs = cl2.predict_proba(X_filtered_test) \n",
    "    probs = probs[:, 1]\n",
    "    auc = roc_auc_score(y_test, probs)  \n",
    "    print('AUC: %.2f' % auc)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probs)  \n",
    "    plot_roc_curve(fpr, tpr) \n",
    "    print(\"Finish [train]...\")\n",
    "    \n",
    "def plot_roc_curve(fpr, tpr):  \n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    rawToRecord()\n",
    "    splitRecord()\n",
    "    combineFiles()\n",
    "    preprocess()\n",
    "    features()\n",
    "    train()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
